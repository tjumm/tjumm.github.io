<!DOCTYPE html>
<html>

  <head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Allan Lab - Publications</title>
  <meta name="description" content="Allan Lab -- Publications.">
  <link rel="stylesheet" href="/css/main.css">
  <link rel="canonical" href="/publications/">
<link rel="shortcut icon" type ="image/x-icon" href="/images/favicon.ico">



</head>


  <body>

    <div class="navbar navbar-default navbar-fixed-top" role="navigation">
  <div class="container-fluid">
	<div class="navbar-header">
	  <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar-collapse-1" aria-expanded="false">
		<span class="sr-only">Toggle navigation</span>
		<span class="icon-bar"></span>
		<span class="icon-bar"></span>
		<span class="icon-bar"></span>
	  </button>
	
    <a class="navbar-brand" href="/">MM Lab @ Tianjin University</a>
	</div>
	<div class="collapse navbar-collapse" id="navbar-collapse-1">
	  <ul class="nav navbar-nav navbar-right">
		<li><a href="/">Home</a></li>
		<li><a href="/research">Research</a></li>
		<li><a href="/team">People</a></li>
		<li><a href="/publications">Publications</a></li>
		<!--<li><a href="/vacancies">Join us</a></li>-->
		<!--<li><a href="/pictures">(Pics)</a></li>-->
	  </ul>
	</div>
  </div>
</div>


    <div class="container-fluid">
      <div class="row">
        <div id="gridid" class="col-sm-12">
  <h1 id="publications">Publications</h1>

<!--## Highlights

(For a full list see [below](#full-list) or go to [Google Scholar](https://scholar.google.ch/citations?user=TqxYWZsAAAAJ), [ResearcherID](https://www.researcherid.com/rid/D-7763-2012))



















































<p> &nbsp; </p>-->

<h2 id="full-list">Full List</h2>

<p>Sequential Video VLAD: Training the Aggregation Locally and Temporally <a href="https://github.com/youjiangxu/seqvlad-pytorch">(code)</a> <br />
  <em>Youjiang Xu, Yahong Han, Richang Hong, Qi Tian </em><br /><a href="https://ieeexplore.ieee.org/document/8382330/">IEEE Transactions on Image Processing (IEEE T-IP)</a></p>

<p>Semi-Supervised Regression with Optimized Rank for Matrix Data Classification  <br />
  <em>Jianguang Zhang, Jianmin Jiang, Yahong Han </em><br /><a href="">IEEE Transactions on Cybernetics (IEEE T-CYB)</a></p>

<p>Multi-modal Circulant Fusion for Video-to-Language and Backward <a href="https://github.com/AmingWu/Multi-modal-Circulant-Fusion">(code)</a> <br />
  <em>Aming Wu, Yahong Han </em><br /><a href="">2018 International Joint Conferences on Artificial Intelligence (IJCAI 2018)</a></p>

<p>Schmidt: Image Augmentation for Black-Box Adversarial Attack <br />
  <em>Yucheng Shi, Yahong Han </em><br /><a href="">IEEE ICME 2018 (Oral Paper)</a></p>

<p>Universal Perturbation Generation for Black-box Attack Using Evolutionary Algorithms <br />
  <em>Siyu Wang, Yucheng Shi, Yahong Han </em><br /><a href="">ICPR 2018</a></p>

<p>Movie Question Answering: Remembering the Textual Cues for Layered Visual Contents<a href="https://github.com/bowong/Layered-Memory-Network">(code)</a><br /><a href="http://movieqa.cs.toronto.edu/workshops/iccv2017/">Winner of the MovieQA and The Large Scale Movie Description Challenge (LSMDC) @ ICCV 2017</a> <br />
  <em>Bo Wang, Youjiang Xu, Yahong Han, Richang Hong </em><br /><a href="">AAAI 2018</a></p>

<p>Catching the Temporal Regions-of-Interest for Video Captioning <a href="https://ziweiyang.github.io/">(Project Page)</a> <br />
  <em>Ziwei Yang, Yahong Han, Zheng Wang </em><br /><a href="">ACM Multimedia 2017 (<b>Oral Paper and Best Paper Presentation</b>)</a></p>

<p>Multirate Multimodal Video Captioning<br /><a href="http://ms-multimedia-challenge.com/2017/challenge#video">The Runner-up of the 2nd MSR Video to Language Challenge</a> <br />
  <em>Ziwei Yang, Youjiang Xu, Huiyun Wang, Bo Wang, Yahong Han </em><br /><a href="">ACM Multimedia 2017 (<b>ACM MM 2017 Grand Challenge <b>Honorable Mention Award</b>)&lt;/a&gt;</b></a></p>

<p>Top Attention in Line with Time: A Light-weight Strategy <a href="https://github.com/youjiangxu/top_attention">(code)</a> <br />
  <em>Youjiang Xu, Shichao Zhao, Yahong Han, Qinghua Hu, Fei Wu </em><br /><a href="">IEEE ICME 2017 (<b>Among Top 3% of the main program paper submissions</b>)</a></p>

<p>Pooling the Convolutional Layers in Deep ConvNets for Video Action Recognition <br />
  <em>Shichao Zhao, Yanbin Liu, Yahong Han, Richang Hong, Qinghua Hu, Qi Tian </em><br /><a href="">IEEE Transactions on Circuits and Systems for Video Technology (IEEE T-CSVT)</a></p>

<p>Semi-Supervised Image-to-Video Adaptation for Video Action Recognition <br />
  <em>Jianguang Zhang, Yahong Han, Jinhui Tang, Qinghua Hu, Jianmin Jiang </em><br /><a href="">IEEE Transactions on Cybernetics (IEEE T-CYB), 2017, 47(4): 960-973</a></p>


</div>

      </div>
    </div>

    <div id="footer" class="panel">
  <div class="panel-footer">
	<div class="container-fluid">
	  <div class="row">
		<center>
		<div class="col-sm-12">
		  Contact: Room B502, Building #55, Tianjin University (<a href="https://j.map.baidu.com/QPmWP">Maps</a>) <br />
			2018-6-1
		</center>
		</div>
	  </div>
	</div>
  </div>
</div>

<script src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.3/jquery.min.js"></script>
<script src="/js/bootstrap.min.js"></script>


  </body>

</html>
